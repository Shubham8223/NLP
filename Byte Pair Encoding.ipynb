{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The BPE (Byte-Pair Encoding) algorithm is a subword tokenization technique used in natural language processing (NLP) and text processing tasks. It was originally developed to handle morphological variations and out-of-vocabulary words in machine translation tasks but has since become popular for a wide range of NLP applications. Here's an overview of how the BPE algorithm works:\n",
        "\n",
        "#Initial Vocabulary Creation:\n",
        "\n",
        "The BPE algorithm starts with an initial vocabulary of characters or subword units (e.g., characters, character pairs, or whole words). Typically, it begins with a vocabulary that includes all the characters in the training data.\n",
        "Tokenization into Subword Units:\n",
        "\n",
        "The input text data is tokenized into subword units based on the initial vocabulary. Initially, each word is separated by spaces and ends with a special end-of-word symbol (e.g., \"</w>\"). For example, the word \"unhappiness\" might be tokenized as \"unhappin ess</w>\".\n",
        "#Frequency Counts:\n",
        "\n",
        "The algorithm calculates the frequency of each subword unit in the training data. It keeps track of the most frequent pairs of adjacent subword units.\n",
        "#Merging the Most Frequent Pair:\n",
        "\n",
        "The pair of adjacent subword units with the highest frequency is merged into a single subword unit. The new subword unit is added to the vocabulary.\n",
        "#Repeat Merging:\n",
        "\n",
        "Steps 3 and 4 are repeated a predetermined number of times or until a certain condition is met (e.g., a fixed vocabulary size is reached).\n",
        "#End Result:\n",
        "\n",
        "The final vocabulary consists of subword units, including characters, character pairs, and whole words. Each word in the input text is tokenized into a sequence of subword units from the vocabulary.\n",
        "The key idea behind BPE is that it starts with a fine-grained vocabulary (characters or character pairs) and progressively merges subword units based on their frequency in the training data. This approach allows BPE to handle morphological variations and effectively represent words that may not be present in the original vocabulary."
      ],
      "metadata": {
        "id": "I6PRZDbUuBz_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRDvJ4vktl6R"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "def build_vocab(corpus):\n",
        "    \"\"\"\n",
        "    Build an initial vocabulary from the corpus.\n",
        "    \"\"\"\n",
        "    vocab = defaultdict(int)\n",
        "    for word in corpus:\n",
        "        chars = list(word)\n",
        "        for char in chars:\n",
        "            vocab[char] += 1\n",
        "    return vocab\n",
        "\n",
        "def get_most_frequent_pair(vocab):\n",
        "    \"\"\"\n",
        "    Get the most frequent pair of adjacent characters in the vocabulary.\n",
        "    \"\"\"\n",
        "    pairs = defaultdict(int)\n",
        "    for word, freq in vocab.items():\n",
        "        chars = list(word)\n",
        "        for i in range(len(chars) - 1):\n",
        "            pairs[chars[i], chars[i + 1]] += freq\n",
        "    most_frequent_pair = max(pairs, key=pairs.get)\n",
        "    return most_frequent_pair\n",
        "\n",
        "def merge_pair(vocab, pair_to_merge):\n",
        "    \"\"\"\n",
        "    Merge the most frequent pair of characters in the vocabulary.\n",
        "    \"\"\"\n",
        "    new_vocab = defaultdict(int)\n",
        "    for word, freq in vocab.items():\n",
        "        new_word = \"\".join(word)\n",
        "        new_word = new_word.replace(\"\".join(pair_to_merge), \"\".join(pair_to_merge))\n",
        "        new_vocab[new_word] += freq\n",
        "    return new_vocab\n",
        "\n",
        "def bpe_tokenization(corpus, num_merges):\n",
        "    \"\"\"\n",
        "    Perform BPE tokenization on the corpus for a specified number of merges.\n",
        "    \"\"\"\n",
        "    vocab = build_vocab(corpus)\n",
        "    for _ in range(num_merges):\n",
        "        most_frequent_pair = get_most_frequent_pair(vocab)\n",
        "        vocab = merge_pair(vocab, most_frequent_pair)\n",
        "    return vocab\n",
        "\n",
        "# Example usage\n",
        "corpus = [\"apple\", \"banana\", \"cherry\", \"date\"]\n",
        "num_merges = 5\n",
        "final_vocab = bpe_tokenization(corpus, num_merges)\n",
        "print(\"Final vocabulary:\", final_vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The termination condition in the Byte-Pair Encoding (BPE) algorithm can vary depending on the specific implementation and requirements of the task. There are a few common termination conditions:\n",
        "\n",
        "#Fixed Vocabulary Size:\n",
        "One common termination condition is to specify a fixed vocabulary size in advance. The algorithm continues merging subword units until the vocabulary size reaches the predefined limit. This ensures that the final vocabulary is of a certain size, which can be useful for controlling the model's memory usage or for consistency across different runs.\n",
        "\n",
        "#Minimum Frequency:\n",
        "Another termination condition is to set a minimum frequency threshold for merging. The algorithm continues merging subword units until no pair of subword units has a frequency greater than the specified threshold. This can be useful for ensuring that subword units with very low frequencies are not included in the final vocabulary.\n",
        "\n",
        "#Maximum Iterations:\n",
        "The algorithm can also terminate after a maximum number of iterations. In each iteration, the most frequent pair of subword units is merged. This approach allows you to control the number of merge operations performed.\n",
        "\n",
        "#Convergence:\n",
        "Some implementations of BPE use convergence as a termination condition. The algorithm continues merging subword units until there is no significant change in the objective function (e.g., the entropy of the vocabulary) or until a convergence threshold is met."
      ],
      "metadata": {
        "id": "8WgPgwnmuUoY"
      }
    }
  ]
}